---
title: ELK Realtime logging
owner: Services
---


## <a id='deprecated'></a> <strong>Deprecated</strong>

This page is deprecated. Please refer to [Elasticsearch](./elasticsearch.html).

## <a id='overview'></a> Overview

The ELK stack consisting of Elasticsearch, Logstash, and Kibana gives the power of centralising log data and provides real-time data insights with intuitive dashboard and robust search capabilities.

## <a id='Quick-Tutorial'></a> Quick Tutorial

1. Create the service: `cf create-service elk small testelk`
1. Bind your app to the service and restart it: `cf bind-service APP_NAME testelk`
1. Create some logs by visiting your web app
1. Connect to [Kibana](#administrating)
1. Create the [index](#index-patterns-creation)
1. See and search through your logs

## <a id='integrating-your-service'></a> Integrating the Service With Your App

After the [creation](../devguide/services/managing-services.html#create) of the service and the [binding](../devguide/services/application-binding.html#bind) of the service to the application, the environment variable [VCAP_SERVICES](../devguide/deploy-apps/environment-variable.html#VCAP-SERVICES) is created. Information about the credentials are stored in this variable as shown here:

```json
{
  "elk": [
    {
      "credentials": {
        "elasticSearchHost": "77gum1z32vota000.service.consul",
        "elasticSearchPassword": "alksdjflaksdjflkal",
        "elasticSearchPort": 51760,
        "elasticSearchUsername": "1laksjdofiasjdfoia",
        "kibanaPassword": "9yqzbtQfcGPRGBDO",
        "kibanaUrl": "http://ajosijfowiqje.service.consul:57627",
        "kibanaUsername": "5E09lqW1log3va97",
        "logstashHost": "jayowj0jalstqaz1c.service.consul",
        "logstashPort": 32301,
        "syslog": "syslog://jayowj0jalstqaz1c.service.consul:32301"
      },
      "label": "elk",
      "name": "iot-logs",
      "plan": "beta",
      "syslog_drain_url": "syslog://jayowj0jalstqaz1c.service.consul:32301",
      "tags": []
    }
  ]
}
```

As soon as the service is bound and the application is restarted, it will start logging all the stdout including router logs automatically to logstash.

## <a id='sample-application'></a> Sample Application

Swisscom: [ELK Example](https://github.com/swisscom/cf-elk-sample)

## <a id='administrating'></a> Administrating your ELK instances

To connect to a running ELK instance with your local development tools, you can use the [`cf ssh`](../devguide/deploy-apps/ssh-services.html) feature of the cf CLI.

Alternatively there is the possiblity to use a proxy app like the Swisscom [Kibana Proxy](https://github.com/swisscom/cf-kibana-proxy) to make your Kibana dashboard available to your browser.

## <a id='index-patterns'></a> Index Patterns

### <a id='index-patterns-creation'></a> Index Patterns creation

To see logs within Kibana an index pattern needs to be created either specifiy the `parsed*` to see the parsed logs.

<%= image_tag("./images/kibana.png") %>

<p class="note"><strong>Hint</strong>:To see unparsed logs create an index pattern named "unparsed*" or create an index pattern "_all" to see all logs within the same index.</p>

### <a id='how-it-works'></a> How It Works

For every app that is bound to an ELK service, the stdout ( `cf logs APP_NAME`) is automatically being sent to the ELK.
Optionally there is a possibility to directly sent logs to the ELK from you app.

<%= image_tag("./images/elk.png") %>

### <a id='patterns'></a> Patterns

All messages that reach Logstash are being processed and send forward to Elasticsearch.
When a message is either in Syslog format or in JSON format, then it can be properly parsed. These messages are going to an index called "parsed-<data>".
Messages that do follow a pattern are going to an index called "unparsed-<data>. In the parsed index are also available by default all messages coming from CF gorouter.

<p class="note">
  <strong>Note</strong>:whether you are sending logs directly from your to ELK or through the stdout, messages will follow the above pattern. Only in the latter case, your log message has been augmented by a CF Prefix.
</p>

In Kibana you can manually set up which index you need, either `parsed*` or/and `unparsed*` or `_all`.

## <a id='logrotation'></a> Logrotation

A new index is saved every day (parsed-2015.12.17). By default for all plans all parsed indexes will be closed every 30 days. This takes them out of memory, which allows Elasticsearch to perform efficientlly, but keeps them on disk, which can be saved (through an Elasticsearch API) or reopened. After 60 days all parsed logs will also be removed from disk. Unparsed indexs will be closed after 5 days and removed from disk after 10 days. If the disk gets full, the oldest logs will be deleted automatically, until disk base usage will be under 90%.

<p class="note">
  <strong>Hint</strong>: To show all indexes within elasticsearch a user can execute the following request: curl "localhost:9200/_cat/indices?v". To open an index a user can execute the following request to elasticsearch: curl -XPOST "localhost:9200/parsed-2015.12.06/_open".
</p>

### <a id='parameters'></a> Parameters

In the future we will also provide service specific parameters for logrotation and similar purposes. This is not yet implemented.
